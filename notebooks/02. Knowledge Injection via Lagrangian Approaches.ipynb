{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Notebook setup\n",
    "# ============================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Control figure size\n",
    "figsize=(14, 4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Knowledge Injection via Lagrangian Approaches\n",
    "\n",
    "Let's start with the classics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangians to the Rescue\n",
    "\n",
    "**A popular way to handle soft constraints in ML is inspired by Lagrangians**\n",
    "\n",
    "Given a learning problem:\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_{\\theta} \\left\\{ L(\\hat{y}) \\mid \\hat{y} = f(x; \\theta) \\right\\}\n",
    "$$\n",
    "\n",
    "And soft constraints modeled as inqualities on a vector function:\n",
    "\n",
    "$$\n",
    "g(\\hat{y}) \\leq 0\n",
    "$$\n",
    "\n",
    "* With $g(\\hat{y}) = \\{g_k(\\hat{y})\\}_k^{m_c}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The idea is to turn the constraints into loss terms**\n",
    "\n",
    "* Doing tha will steer the model towards satisfying the constraints\n",
    "* ...And can be though of as a form of regularization\n",
    "\n",
    "In fact, an early example of this approach is called [Semantic Based Regularization](https://www.sciencedirect.com/science/article/pii/S0004370215001344)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangian-like Loss\n",
    "\n",
    "**In practice, we usually form a modified, Lagrangian-like, loss:**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\lambda) = L(\\hat{y}) + \\lambda^T h(g(\\hat{y}))\n",
    "$$\n",
    "\n",
    "Where $h$ is sometimes referred to as a _penalizer_\n",
    "\n",
    "* Intuitively, we don't use the constraint violation as it is\n",
    "* ...But we build a function based on its value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Why the penalizer instead of using a classic Lagrangian?**\n",
    "\n",
    "...Which by the way would be:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\lambda) = L(\\hat{y}) + \\lambda^T g(\\hat{y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> **There are two main, non-trivial, reasons**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Stop-gain Mechanism\n",
    "\n",
    "**We are considering inequality constraints**\n",
    "\n",
    "$$\n",
    "g(\\hat{y}) \\leq 0\n",
    "$$\n",
    "\n",
    "* Predictions with $g_k(\\hat{y}) < 0$ are equivalent to those with $g_k(\\hat{y}) = 0$\n",
    "* ...But in a classical Lagrangian approach a slack translates to a _reward_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In classical Lagrangian theory, this is avoided by the KKT coditions**\n",
    "\n",
    "...And in particular by complementary slackness:\n",
    "\n",
    "$$\n",
    "\\lambda \\odot g(\\hat{y}) = 0\n",
    "$$\n",
    "\n",
    "* This condition can only be achieved by updating $\\lambda$ and $\\hat{y}$ together\n",
    "* ...And typically some specialized optimization algorithm\n",
    "\n",
    "When $\\hat{y}$ comes from a non-linear model, the condition is tricky to achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Stop-gain Mechanism\n",
    "\n",
    "**However, there's a far easier alternative**\n",
    "\n",
    "We can just use non-linearity to remove the reward effect, e.g. by clipping:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\lambda) = L(\\hat{y}) + \\lambda^T \\max(0, g(\\hat{y}))\n",
    "$$\n",
    "\n",
    "* The maximum operator will neutralized any reward when $g_k(\\hat{y}) < 0$\n",
    "* ...Which is effectively equivalent to forcing $\\lambda_k$ to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**With the new penalizer:**\n",
    "\n",
    "* When all constraints are feasible, we preserve the original loss function\n",
    "* When a constraint is infeasible, we introduce a penalty\n",
    "\n",
    "And this is true _as long as $\\lambda \\geq 0$_\n",
    "\n",
    "**This approach comes from [penalty methods](https://en.wikipedia.org/wiki/Penalty_method#:~:text=Penalty%20methods%20are%20a%20certain,of%20the%20original%20constrained%20problem.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Semantic-based Calibration\n",
    "\n",
    "**Using a clipped penalizer makes it also easier to choose the multipliers**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\lambda) = L(\\hat{y}) + \\lambda^T \\max(0, g(\\hat{y}))\n",
    "$$\n",
    "\n",
    "* There's no more need to optimize $\\hat{y}$ (i.e. $\\theta$) and $\\lambda$ together\n",
    "* ...Since any _fixed_ vector $\\lambda \\geq 0$ will result in meaningful penalties\n",
    "\n",
    "> **But how should we choose a $\\lambda$ vector among the valid ones?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**This is made trickier by the fact that we have _soft_ constraints**\n",
    "\n",
    "* We exepect our constraints to be useful\n",
    "* ...But we don't want them satisfied at the expense of accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Semantic-based Calibration\n",
    "\n",
    "**In theory, there's a simple approach for calibrating $\\lambda$**\n",
    "\n",
    "* Since our goal is to improve accuracy\n",
    "* ...We can just assess the quality of a $\\lambda$ vector by _cross-validation_\n",
    "* Then we can search for an optimal $\\lambda$\n",
    "\n",
    "In practice, however, this approach _doest not always work_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**In most cases, knowledge injection is used when _supervised data is scarce_**\n",
    "\n",
    "...And in this situation cross-validation is not very reliable\n",
    "\n",
    "* We can optimize the training-set accuracy instead\n",
    "* ...But that comes at the risk of overfitting\n",
    "\n",
    "> **Is there an alternative?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Semantic-based Calibration\n",
    "\n",
    "**In general, calibrating $\\lambda$ is still an open problem**\n",
    "\n",
    "...But we can make it simpler by thinking a bit about the penalizer semantic:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\lambda) = L(\\hat{y}) + \\lambda^T \\max(0, g(\\hat{y}))\n",
    "$$\n",
    "\n",
    "A key difficulty here is that the two loss terms use _different \"currencies\"_\n",
    "\n",
    "* In most cases, $L(\\hat{y})$ will represent a (negative) log likelihood\n",
    "* While each $\\max(0, g_k(\\hat{y}))$ represents a violation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**A way around this issue consists in _converting the currency_**\n",
    "\n",
    "Typically, we link the violation to a probability\n",
    "\n",
    "* This can be done by assuming a (prior) distribution for constrait violation\n",
    "* ...And then deriving a penalizer based on that assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Semantic-based Calibration\n",
    "\n",
    "**Let's make an example for a (scalar) constraint $g_k(\\hat{y}) \\leq 0$**\n",
    "\n",
    "The violation is given by:\n",
    "\n",
    "$$\n",
    "\\max(0, g_k(\\hat{y}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Let's assume it is associated to an _exponential distribution_ with rate $\\gamma$:**\n",
    "\n",
    "$$\n",
    "P(\\hat{y} \\mid x) = \\gamma e^{-\\gamma \\max(0, g_k(\\hat{y}))} \\quad \\text{ conditional, since: } \\hat{y} = f(x; \\theta)\n",
    "$$\n",
    "\n",
    "Using an exponential is a reasonable choice for a soft-constraint in regression:\n",
    "\n",
    "* It means we expect small violations to be quite likely\n",
    "* ...But large violations to be very rare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Semantic-based Calibration\n",
    "\n",
    "**We can now derive the corresponding (negative) log likelihood:**\n",
    "\n",
    "$$\n",
    "-\\log P(\\hat{y} \\mid x) = -\\log \\gamma + \\gamma \\max(0, g_k(\\hat{y}))\n",
    "$$\n",
    "\n",
    "Since we focus on optimization, we don't care about constant terms:\n",
    "\n",
    "$$\n",
    "\\mathop{\\rm argmin}_{\\hat{y}} - \\log P(\\hat{y} \\mid x) = \\mathop{\\rm argmin}_{\\hat{y}} \\left( \\gamma \\max(0, g_k(\\hat{y})) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plugging the main loss and iterating on all constraints we get:\n",
    "\n",
    "$$\n",
    "L(\\hat{y}) + \\gamma^T \\max(0, g(\\hat{y}))\n",
    "$$\n",
    "\n",
    "* ...Which is essentially our Lagrangian-like loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Semantic-based Calibration\n",
    "\n",
    "**In doing this, we've learned something**\n",
    "\n",
    "In our Lagrangian-like loss:\n",
    "\n",
    "$$\n",
    "L(\\hat{y}) + \\lambda^T \\max(0, g(\\hat{y}))\n",
    "$$\n",
    "\n",
    "* $\\lambda$ represents a vector of _rates_ for exponential distributions\n",
    "* ...Which enables using _domain expertise_ to calibrate the multipliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The same approach can be used in other settings**\n",
    "\n",
    "...We just need to make suitable assumptions\n",
    "\n",
    "* E.g. on classification problems our constraints might be binary predicates\n",
    "* ...And we might want to use a Bernoulli distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Equality Constraints\n",
    "\n",
    "**Equality constraints allow for a simpler formulation**\n",
    "\n",
    "In principle, given an equality constraint:\n",
    "\n",
    "$$\n",
    "g_k(\\hat{y}) = 0\n",
    "$$\n",
    "\n",
    "We can state it as two inequality constraints:\n",
    "\n",
    "$$\n",
    "g_k(\\hat{y}) \\leq 0 \\quad \\text{and} \\quad -g_k(\\hat{y}) \\leq 0\n",
    "$$\n",
    "\n",
    "...And build two (weighted) violation terms:\n",
    "\n",
    "$$\n",
    "\\lambda_k' \\max\\left(0, g_k(\\hat{y})\\right) \\quad \\text{and} \\quad \\lambda_k''  \\max\\left(0, -g_k(\\hat{y})\\right)\n",
    "$$\n",
    "\n",
    "* With $\\lambda_k', \\lambda_k'' \\geq 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Equality Constraints\n",
    "\n",
    "**Summing the two terms leads to a simplified formula**\n",
    "\n",
    "$$\n",
    "\\lambda_k' \\max\\left(0, g_k(\\hat{y})\\right) + \\lambda_k''  \\max\\left(0, -g_k(\\hat{y})\\right) = \\lambda_k |g_k(\\hat{y})|\n",
    "$$\n",
    "\n",
    "* Where $\\lambda_k = \\lambda_k' + \\lambda_k''$ and there is no sign restriction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**In this situation, it also makes sense to assume a _Normal distribution_**\n",
    "\n",
    "$$\n",
    "P(\\hat{y} \\mid x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{g(\\hat{y})^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "From which we can derive the loss:\n",
    "\n",
    "$$\n",
    "L(\\hat{y}) + \\lambda^T g(\\hat{y})^2\n",
    "$$\n",
    "\n",
    "* Where $\\lambda$ corresponds to: $1/(2\\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Differentiability\n",
    "\n",
    "**It's worth talking about differentiability**\n",
    "\n",
    "* Lagangian approaches for knowledge injection\n",
    "* ...Are most common with differentiable constraints\n",
    "\n",
    "...Even if differentiability is _not strictly needed_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Differentiability _might_ be needed**\n",
    "\n",
    "...Depending on which training algorithms is used, e.g.:\n",
    "\n",
    "* Gradient descent\n",
    "* Gradient boosting\n",
    "* ...\n",
    "\n",
    "...Which means that we need differentiability when using Neural Networks"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "rise": {
   "center": false,
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
