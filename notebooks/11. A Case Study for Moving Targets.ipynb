{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook setup: run this before everything\n",
    "# ============================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Control figure size\n",
    "figsize=(14, 5)\n",
    "\n",
    "from util import util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Specify data folder\n",
    "fname = os.path.join('..', 'data', 'winequality-white.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Case Study for Moving Targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Case Study for Moving Targets\n",
    "\n",
    "**Let's consider a more practical use case for MT**\n",
    "\n",
    "We will still tackle a synthetic problem, but one closer to practice\n",
    "\n",
    "* In particular, given a classification problem\n",
    "* We will require to have roughly balance class predictions\n",
    "\n",
    "$$\n",
    "\\left| \\sum_{i = 1}^{m} z_{ij} - \\frac{m}{n_c} \\right| \\leq \\beta \\frac{m}{n_c}, \\quad \\forall j \\in 1..n_c\n",
    "$$\n",
    "\n",
    "* Where $z_{ij} = 1$ iff the classifier predicts class $j$ for example $i$\n",
    "* I.e. the result of an argmax applied to the output of a probabilistic classifier\n",
    "\n",
    "**...Basically, this the example from the previous section**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Dataset \n",
    "\n",
    "**We will use the [\"wine quality\" dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) from UCI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality_3</th>\n",
       "      <th>quality_4</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality_3  quality_4  quality_5  quality_6  quality_7  quality_8  \\\n",
       "0      8.8      False      False      False       True      False      False   \n",
       "1      9.5      False      False      False       True      False      False   \n",
       "2     10.1      False      False      False       True      False      False   \n",
       "3      9.9      False      False      False       True      False      False   \n",
       "4      9.9      False      False      False       True      False      False   \n",
       "\n",
       "   quality_9  \n",
       "0      False  \n",
       "1      False  \n",
       "2      False  \n",
       "3      False  \n",
       "4      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = util.load_classification_dataset(fname, onehot_inputs=['quality'])\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will learn a model to predict wine quality\n",
    "* There are 7 possible classes, represented via a one-hot encoding\n",
    "* An ordinal encoding would be better, but our choice makes for a better example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "**We perform pre-processing as usual**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "      <td>1.469000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.235960e-16</td>\n",
       "      <td>1.475259e-16</td>\n",
       "      <td>-1.934766e-16</td>\n",
       "      <td>1.644551e-16</td>\n",
       "      <td>-1.015752e-16</td>\n",
       "      <td>-1.813843e-16</td>\n",
       "      <td>1.463167e-16</td>\n",
       "      <td>-8.416231e-15</td>\n",
       "      <td>-4.198442e-15</td>\n",
       "      <td>3.337471e-16</td>\n",
       "      <td>7.255372e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "      <td>1.000341e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.513954e+00</td>\n",
       "      <td>-1.981296e+00</td>\n",
       "      <td>-2.750607e+00</td>\n",
       "      <td>-1.170902e+00</td>\n",
       "      <td>-1.436585e+00</td>\n",
       "      <td>-1.916670e+00</td>\n",
       "      <td>-2.969922e+00</td>\n",
       "      <td>-2.338980e+00</td>\n",
       "      <td>-2.511541e+00</td>\n",
       "      <td>-2.086077e+00</td>\n",
       "      <td>-2.046688e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.396233e-01</td>\n",
       "      <td>-6.660564e-01</td>\n",
       "      <td>-5.421591e-01</td>\n",
       "      <td>-9.256225e-01</td>\n",
       "      <td>-4.519909e-01</td>\n",
       "      <td>-6.550002e-01</td>\n",
       "      <td>-7.262526e-01</td>\n",
       "      <td>-7.862395e-01</td>\n",
       "      <td>-6.881092e-01</td>\n",
       "      <td>-7.002723e-01</td>\n",
       "      <td>-8.300787e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.080447e-02</td>\n",
       "      <td>-1.601951e-01</td>\n",
       "      <td>-1.331873e-01</td>\n",
       "      <td>-2.306630e-01</td>\n",
       "      <td>-1.387109e-01</td>\n",
       "      <td>-8.151391e-02</td>\n",
       "      <td>-1.309932e-01</td>\n",
       "      <td>-5.839245e-02</td>\n",
       "      <td>-1.020061e-01</td>\n",
       "      <td>-9.398282e-02</td>\n",
       "      <td>-1.001133e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.580144e-01</td>\n",
       "      <td>4.468384e-01</td>\n",
       "      <td>4.393732e-01</td>\n",
       "      <td>7.197965e-01</td>\n",
       "      <td>1.745692e-01</td>\n",
       "      <td>5.493210e-01</td>\n",
       "      <td>6.474229e-01</td>\n",
       "      <td>7.387734e-01</td>\n",
       "      <td>5.492195e-01</td>\n",
       "      <td>5.123066e-01</td>\n",
       "      <td>7.109594e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.821714e+00</td>\n",
       "      <td>4.898418e+00</td>\n",
       "      <td>5.347035e+00</td>\n",
       "      <td>4.031074e+00</td>\n",
       "      <td>1.006527e+01</td>\n",
       "      <td>1.454239e+01</td>\n",
       "      <td>6.897646e+00</td>\n",
       "      <td>3.112941e+00</td>\n",
       "      <td>4.065838e+00</td>\n",
       "      <td>5.102784e+00</td>\n",
       "      <td>2.819749e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity   citric acid  residual sugar  \\\n",
       "count   1.469000e+03      1.469000e+03  1.469000e+03    1.469000e+03   \n",
       "mean    5.235960e-16      1.475259e-16 -1.934766e-16    1.644551e-16   \n",
       "std     1.000341e+00      1.000341e+00  1.000341e+00    1.000341e+00   \n",
       "min    -3.513954e+00     -1.981296e+00 -2.750607e+00   -1.170902e+00   \n",
       "25%    -6.396233e-01     -6.660564e-01 -5.421591e-01   -9.256225e-01   \n",
       "50%    -4.080447e-02     -1.601951e-01 -1.331873e-01   -2.306630e-01   \n",
       "75%     5.580144e-01      4.468384e-01  4.393732e-01    7.197965e-01   \n",
       "max     8.821714e+00      4.898418e+00  5.347035e+00    4.031074e+00   \n",
       "\n",
       "          chlorides  free sulfur dioxide  total sulfur dioxide       density  \\\n",
       "count  1.469000e+03         1.469000e+03          1.469000e+03  1.469000e+03   \n",
       "mean  -1.015752e-16        -1.813843e-16          1.463167e-16 -8.416231e-15   \n",
       "std    1.000341e+00         1.000341e+00          1.000341e+00  1.000341e+00   \n",
       "min   -1.436585e+00        -1.916670e+00         -2.969922e+00 -2.338980e+00   \n",
       "25%   -4.519909e-01        -6.550002e-01         -7.262526e-01 -7.862395e-01   \n",
       "50%   -1.387109e-01        -8.151391e-02         -1.309932e-01 -5.839245e-02   \n",
       "75%    1.745692e-01         5.493210e-01          6.474229e-01  7.387734e-01   \n",
       "max    1.006527e+01         1.454239e+01          6.897646e+00  3.112941e+00   \n",
       "\n",
       "                 pH     sulphates       alcohol  \n",
       "count  1.469000e+03  1.469000e+03  1.469000e+03  \n",
       "mean  -4.198442e-15  3.337471e-16  7.255372e-17  \n",
       "std    1.000341e+00  1.000341e+00  1.000341e+00  \n",
       "min   -2.511541e+00 -2.086077e+00 -2.046688e+00  \n",
       "25%   -6.881092e-01 -7.002723e-01 -8.300787e-01  \n",
       "50%   -1.020061e-01 -9.398282e-02 -1.001133e-01  \n",
       "75%    5.492195e-01  5.123066e-01  7.109594e-01  \n",
       "max    4.065838e+00  5.102784e+00  2.819749e+00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtout = [c for c in data.columns if c.startswith('quality_')]\n",
    "dtin = [c for c in data.columns if c not in dtout]\n",
    "trl, tsl, scalers = util.split_datasets([data], fraction=0.7, seed=42, standardize=dtin)\n",
    "tr, ts, scaler = trl[0], tsl[0], scalers[0]\n",
    "tr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dataset Balance\n",
    "\n",
    "**We can use the (avg. of) our constraint metric to assess the dataset balance:**\n",
    "\n",
    "$$\n",
    "\\frac{1}{n_c} \\sum_{j=1}^{n_c} \\left| \\sum_{i = 1}^{m} z_{ij} - \\frac{m}{n_c} \\right|, \\quad \\forall j \\in 1..n_c\n",
    "$$\n",
    "\n",
    "* Where $\\hat{z}$ are the class columns (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original avg deviation: 101.42% (training), 98.71% (test)\n"
     ]
    }
   ],
   "source": [
    "bal_thr = 0.3\n",
    "tr_true = np.argmax(tr[dtout].values, axis=1)\n",
    "ts_true = np.argmax(ts[dtout].values, axis=1)\n",
    "tr_bal_src = util.avg_bal_deviation(tr_true, bal_thr, nclasses=len(dtout))\n",
    "ts_bal_src = util.avg_bal_deviation(ts_true, bal_thr, nclasses=len(dtout))\n",
    "print(f'Original avg deviation: {tr_bal_src*100:.2f}% (training), {ts_bal_src*100:.2f}% (test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our goal will be to push the balance deviation down to 30%\n",
    "* I.e. we will assume $\\beta = 0.3$ in the constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Learner\n",
    "\n",
    "**Our \"learner\" will be a multilayer perceptron**\n",
    "\n",
    "The code can be found as usual in the `util` module\n",
    "\n",
    "```python\n",
    "class MLPLearner(object):\n",
    "    def __init__(self, hidden, epochs=20, batch_size=32,\n",
    "            epochs_fine_tuning=None, verbose=0): ...\n",
    "\n",
    "    def fit(self, X, y): ...\n",
    "\n",
    "    def predict_proba(self, X): ...\n",
    "\n",
    "    def predict(self, X): ...\n",
    "```\n",
    "\n",
    "* We are using a standard scikit-learn API\n",
    "* ...With the ability to use different \\#epochs for the first and subsequent training\n",
    "* ...Which will prove useful later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Learner\n",
    "\n",
    "**Let's start by checking how regular training fares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67 (training), 0.55 (test)\n",
      "Classifier avg deviation: 119% (training), 124% (test)\n",
      "Balance violation threshold: 30%\n"
     ]
    }
   ],
   "source": [
    "learner = XGBClassifier(n_estimators=20, max_depth=2, learning_rate=0.5, objective='binary:logistic')\n",
    "learner.fit(tr[dtin].values, tr[dtout].values)\n",
    "tr_pred_prob = learner.predict_proba(tr[dtin])\n",
    "ts_pred_prob = learner.predict_proba(ts[dtin])\n",
    "tr_acc, tr_bal = util.mt_balance_stats(tr[dtout].values, tr_pred_prob, bal_thr)\n",
    "ts_acc, ts_bal = util.mt_balance_stats(ts[dtout].values, ts_pred_prob, bal_thr)\n",
    "print(f'Accuracy: {tr_acc:.2f} (training), {ts_acc:.2f} (test)')\n",
    "print(f'Classifier avg deviation: {tr_bal*100:.0f}% (training), {ts_bal*100:.0f}% (test)')\n",
    "print(f'Balance violation threshold: {bal_thr*100:.0f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The tets accuracy is slightly above 50%\n",
    "* ...But the balance violation is far larger than our threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Master\n",
    "\n",
    "**The master step is implemented via an Or-tools model**\n",
    "\n",
    "```python\n",
    "def mt_balance_master(y_true, y_pred, bal_thr, rho=1, ...):\n",
    "    # Build a model\n",
    "    slv = pywraplp.Solver.CreateSolver('SAT')\n",
    "    ...\n",
    "    # Solve\n",
    "    status = slv.Solve()\n",
    "    ...\n",
    "    # Return the solution and stats\n",
    "    return sol, stats\n",
    "```\n",
    "\n",
    "* `y_true` corresponds to $\\hat{y}$ and `y_pred` to the current prediction vector\n",
    "* The balance threshold `bal_thr` is a fractional value\n",
    "* A mode parameter allows one to adjust a bit the problem behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Master\n",
    "\n",
    "**The master step is implemented via an Or-tools model**\n",
    "\n",
    "```python\n",
    "def mt_balance_master(y_true, y_pred, bal_thr, rho=1, ...):\n",
    "    ...\n",
    "    # Build target variables\n",
    "    z = {(i,j) : slv.IntVar(0, 1, f'z[{i},{j}]') for i in range(ns) for j in range(nc)}\n",
    "    # Unique class constraints\n",
    "    for i in range(ns):\n",
    "        slv.Add(sum(z[i, j] for j in range(nc)) == 1)\n",
    "    ...\n",
    "```\n",
    "\n",
    "* We are using integer variables for the targets\n",
    "* ...Which is consistent with the semantic of our constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Master\n",
    "\n",
    "**The master step is implemented via an Or-tools model**\n",
    "\n",
    "```python\n",
    "def mt_balance_master(y_true, y_pred, bal_thr, rho=1, ...):\n",
    "    ...\n",
    "    # Add the balance constraint\n",
    "    ref = ns / nc\n",
    "    for j in range(nc):\n",
    "        slv.Add(sum(z[i, j] for i in range(ns)) <= ref + ref * bal_thr)\n",
    "        slv.Add(sum(z[i, j] for i in range(ns)) >= ref - ref * bal_thr)\n",
    "    ...\n",
    "```\n",
    "\n",
    "* The balance constraint is implemented via two inequalities\n",
    "* Class counts are easy to compute by relying on integer one-hot targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Master\n",
    "\n",
    "**The master step is implemented via an Or-tools model**\n",
    "\n",
    "```python\n",
    "def mt_balance_master(y_true, y_pred, bal_thr, rho=1, ...):\n",
    "    ...\n",
    "    # Build the loss w.r.t. the original target\n",
    "    loss_t = 0\n",
    "    for i in range(ns):\n",
    "        for j in range(nc):\n",
    "            loss_t += y_true[i, j] * (1 - z[i, j])\n",
    "    ...\n",
    "```\n",
    "\n",
    "* As a loss $L$ for the master, the categorical crossed-entropy\n",
    "* ...With logarithms capped and scaled by $\\log \\varepsilon$\n",
    "* The formula can be simplified since the original targets are 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Master\n",
    "\n",
    "**The master step is implemented via an Or-tools model**\n",
    "\n",
    "```python\n",
    "def mt_balance_master(y_true, y_pred, bal_thr, rho=1, ...):\n",
    "    ...\n",
    "    # Build the quadratic part of the objective\n",
    "    loss_p = 0\n",
    "    for i in range(ns):\n",
    "        for j in range(nc):\n",
    "            loss_p += z[i, j] * scaled_pred_cnl[i, j]\n",
    "    # Define the cost function\n",
    "    slv.Minimize(loss_t + 1/rho * loss_p)\n",
    "    ...\n",
    "```\n",
    "\n",
    "* We use the scaled cross-entropy for the loss w.r.t. the predictions, too\n",
    "* ...But no simplification is possible, since the predictions are continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loss-driven Projection\n",
    "\n",
    "**A simpler approach to inject constraints in the ML model...**\n",
    "\n",
    "...Starts by directly \"projecting\" the ground truth $\\hat{y}$ in feasible space\n",
    "\n",
    "* This can be obtained by setting $\\rho = \\infty$\n",
    "* The projection can be done using the loss itself as a distance:\n",
    "\n",
    "$$\n",
    "\\text{argmin}_{z} \\left\\{ L(z, \\hat{y}) \\mid z \\in C \\right\\}\n",
    "$$\n",
    "\n",
    "**By doing this, we can obtain the _best possible_ feasible target vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62, Balance deviation: 25.38%, Optimal solution: True\n",
      "CPU times: user 8.88 s, sys: 77.6 ms, total: 8.96 s\n",
      "Wall time: 865 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "zp, stats = util.mt_balance_master(tr[dtout].values, tr[dtout].values, bal_thr, time_limit=10, rho=np.inf, solver='SAT')\n",
    "tmp_acc, tmp_bal = util.mt_balance_stats(tr[dtout].values, zp, bal_thr)\n",
    "print(f'Accuracy: {tmp_acc:.2f}, Balance deviation: {tmp_bal*100:.2f}%, Optimal solution: {stats[\"opt\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loss-driven Projection\n",
    "\n",
    "**Then, the simple approach consists training against this \"ideal\" vector**\n",
    "\n",
    "The method is implemented in `util` as part of the MT code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57 (training), 0.40 (test)\n",
      "Classifier balance violation: 58% (training), 66% (test)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "learner_prj = XGBClassifier(n_estimators=50, max_depth=2, learning_rate=0.5, objective='binary:logistic')\n",
    "util.mt_balance(tr[dtin].values, tr[dtout].values, learner_prj, bal_thr, rho=np.inf, master_tlim=10, eps=1e-4);\n",
    "tr_pred_prob = learner_prj.predict_proba(tr[dtin])\n",
    "ts_pred_prob = learner_prj.predict_proba(ts[dtin])\n",
    "tr_acc, tr_bal = util.mt_balance_stats(tr[dtout].values, tr_pred_prob, bal_thr)\n",
    "ts_acc, ts_bal = util.mt_balance_stats(ts[dtout].values, ts_pred_prob, bal_thr)\n",
    "print(f'Accuracy: {tr_acc:.2f} (training), {ts_acc:.2f} (test)')\n",
    "print(f'Classifier balance violation: {tr_bal*100:.0f}% (training), {ts_bal*100:.0f}% (test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The constraint violation is still too high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Moving Targets\n",
    "\n",
    "**Let's now test the actual MT method**\n",
    "\n",
    "We use fewer training epochs after the first `fit` call to speed up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#1) l-acc: 0.52, l-bal: 0.37, l-time: 0.28s, m-acc: 0.59, l-m dist: 2.08, m-time: 0.49s\n",
      "(#2) l-acc: 0.52, l-bal: 0.32, l-time: 0.28s, m-acc: 0.58, l-m dist: 0.62, m-time: 0.46s\n",
      "(#3) l-acc: 0.53, l-bal: 0.29, l-time: 0.27s, m-acc: 0.57, l-m dist: 0.54, m-time: 0.43s\n",
      "(#4) l-acc: 0.52, l-bal: 0.29, l-time: 0.28s, m-acc: 0.57, l-m dist: 0.50, m-time: 0.43s\n",
      "(#5) l-acc: 0.53, l-bal: 0.29, l-time: 0.27s, m-acc: 0.57, l-m dist: 0.47, m-time: 0.46s\n",
      "(#6) l-acc: 0.52, l-bal: 0.29, l-time: 0.27s, m-acc: 0.56, l-m dist: 0.45, m-time: 0.49s\n",
      "(#7) l-acc: 0.52, l-bal: 0.30, l-time: 0.27s, m-acc: 0.56, l-m dist: 0.43, m-time: 0.45s\n",
      "(#8) l-acc: 0.52, l-bal: 0.29, l-time: 0.27s, m-acc: 0.56, l-m dist: 0.42, m-time: 0.44s\n",
      "(#9) l-acc: 0.53, l-bal: 0.30, l-time: 0.27s, m-acc: 0.56, l-m dist: 0.41, m-time: 0.44s\n",
      "(#10) l-acc: 0.53, l-bal: 0.29, l-time: 0.27s, m-acc: 0.56, l-m dist: 0.41, m-time: 0.45s\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "rho, max_iter = 0.1, 10\n",
    "learner_mt = XGBClassifier(n_estimators=50, max_depth=2, learning_rate=0.5, objective='binary:logistic')\n",
    "util.mt_balance(tr[dtin].values, tr[dtout].values, learner_mt, bal_thr, rho=rho, max_iter=max_iter, master_tlim=10, verbose=1, use_deterministic_pred=False, eps=1e-5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Constraint satisfaction improves across iterations\n",
    "* The learner/master accuracy tends to decrease/increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Moving Targets\n",
    "\n",
    "**Let's check generalization over the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53 (training), 0.34 (test)\n",
      "Classifier balance deviation: 29% (training), 28% (test)\n"
     ]
    }
   ],
   "source": [
    "tr_pred_prob = learner_mt.predict_proba(tr[dtin])\n",
    "ts_pred_prob = learner_mt.predict_proba(ts[dtin])\n",
    "tr_acc, tr_bal = util.mt_balance_stats(tr[dtout].values, tr_pred_prob, bal_thr)\n",
    "ts_acc, ts_bal = util.mt_balance_stats(ts[dtout].values, ts_pred_prob, bal_thr)\n",
    "print(f'Accuracy: {tr_acc:.2f} (training), {ts_acc:.2f} (test)')\n",
    "print(f'Classifier balance deviation: {tr_bal*100:.0f}% (training), {ts_bal*100:.0f}% (test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do have some overfitting in terms of accuracy\n",
    "\n",
    "* This is due to the fact that we have very restrictive constraints\n",
    "* ...And they directly oppose information in the data\n",
    "\n",
    "Constraint satisfaction generalizes without issues\n",
    "\n",
    "* ...And this is a big deal!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "rise": {
   "center": false,
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
